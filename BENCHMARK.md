# big-json-handler Performance Benchmarks

## ğŸš€ Running Benchmarks

```bash
# Run comprehensive performance comparison
npm run benchmark

# Or manually with garbage collection enabled
npm run build
node --expose-gc dist/test/benchmark.js
```

## ğŸ“Š What We Test

### Test Categories

1. **ğŸ”¢ Array Processing**
   - Small Array: 1,000 elements
   - Medium Array: 10,000 elements  
   - Large Array: 100,000 elements

2. **ğŸ—‚ï¸ Object Processing**
   - Small Object: 1,000 properties
   - Medium Object: 10,000 properties
   - Large Object: 50,000 properties

3. **ğŸ—ï¸ Complex Nested Structures**
   - 1,000 user objects with nested metadata and arrays

## ğŸ“ˆ Key Performance Insights

### Where big-json-handler Excels ğŸ†

| Scenario | Performance Gain | Use Case |
|----------|------------------|----------|
| **Large Objects** (50K props) | **2.7x faster** + 26% less memory | Database exports, config files |
| **Medium Objects** (10K props) | **1.6x faster** + 248% less memory | API responses, data processing |
| **Large Arrays** (100K items) | 79% less memory usage | Log processing, bulk data |

### Where JSON.parse Wins ğŸ¥‡

| Scenario | Performance Gap | Recommendation |
|----------|----------------|----------------|
| **Small Arrays** (1K items) | 5.4x faster | Use JSON.parse for small datasets |
| **Complex Nested** | 3.9x faster | Use JSON.parse for complex structures |

## ğŸ¯ Performance Decision Matrix

### Choose big-json-handler when:

```
âœ… File size > 10MB
âœ… Memory usage is critical
âœ… Processing flat/simple structures  
âœ… Only need specific fields from large datasets
âœ… Running in memory-constrained environments (Lambda, containers)
```

### Choose JSON.parse when:

```
âœ… File size < 1MB
âœ… Need random access to data
âœ… Working with complex nested structures
âœ… Rapid development/prototyping
âœ… Small arrays or objects
```

## ğŸ§ª Benchmark Methodology

### Memory Measurement
- Uses `process.memoryUsage()` before/after parsing
- Includes forced garbage collection with `--expose-gc`
- Measures heap usage difference

### Performance Metrics
- **Duration**: Total parsing + processing time (milliseconds)
- **Throughput**: Items processed per second
- **Memory**: Peak heap memory increase (MB)

### Test Data Generation
- **Arrays**: Sequential integers `[0, 1, 2, ...]`
- **Objects**: Simple key-value pairs `{"key0": 0, "key1": 1, ...}`
- **Complex**: Realistic nested user objects with metadata

## ğŸ“Š Interpreting Results

The benchmark outputs a colorized table showing:

- ğŸŸ¢ **Green**: Better performance (faster or less memory)
- ğŸ”´ **Red**: Worse performance (slower or more memory)  
- ğŸŸ¡ **Yellow**: Similar performance (within 20% difference)

### Sample Output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test Case           â”‚ JSON.parse           â”‚ big-json-handler     â”‚ Speed Ratio    â”‚ Memory Ratio   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Large Object (50K)  â”‚ 17.6ms 10.69MB       â”‚ 6.5ms 8.52MB        â”‚ 2.70x faster   â”‚ 1.26x less     â”‚
â”‚ Small Array (1K)    â”‚ 0.2ms 0.37MB         â”‚ 0.9ms 0.78MB        â”‚ 5.43x slower   â”‚ 0.47x more     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Custom Benchmarks

You can modify test parameters in `test/benchmark.ts`:

```typescript
const testCases = [
  { name: 'Huge Array (1M)', size: 1000000, type: 'array' },
  { name: 'Massive Object (100K)', size: 100000, type: 'object' },
  // Add your custom test cases
];
```

## ğŸ’¡ Real-world Performance Tips

1. **Profile Your Actual Data**: Run benchmarks with your real JSON structures
2. **Consider File Size vs Structure**: Large simple structures favor big-json-handler
3. **Memory vs Speed Trade-offs**: Choose based on your constraints
4. **Early Exit Strategies**: Implement early termination in your parsing logic

## ğŸ† Performance Best Practices

### For big-json-handler:
```typescript
// âœ… Good - Early exit when found
for (const {key, value} of iterator) {
  if (sjGetString(reader, key) === 'target') {
    processValue(value);
    break; // Stop parsing unnecessary data
  }
}

// âŒ Bad - Parse everything
const allData = Array.from(iterator);
const target = allData.find(item => /* condition */);
```

### For JSON.parse:
```typescript
// âœ… Good - For small, complex data
const data = JSON.parse(smallComplexJson);
const result = processComplexStructure(data);

// âŒ Bad - For large simple data  
const data = JSON.parse(hugeSimpleJson); // Memory spike
```

## ğŸ“ˆ Scaling Characteristics

### big-json-handler Scaling:
- **Memory**: Constant O(1) regardless of JSON size
- **Speed**: Linear O(n) with data processed, not total size
- **Best Case**: Large flat structures (objects/arrays)

### JSON.parse Scaling:
- **Memory**: Linear O(n) with JSON size
- **Speed**: Highly optimized, but affected by total size
- **Best Case**: Small to medium complex structures

---

**Run the benchmarks with your own data to make informed decisions!** ğŸš€